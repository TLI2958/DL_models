{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NwLQOFMMlev"
   },
   "source": [
    "# Computer Vision Assignment 1 Part 1\n",
    "---\n",
    "\n",
    "Semester: **Fall 2023**\n",
    "\n",
    "Due date: **October 5th 2023, 11.59PM EST.**\n",
    "\n",
    "## Introduction\n",
    "---\n",
    "\n",
    "This assignment is an introduction to using PyTorch for training simple neural net models. Two different datasets will be used:\n",
    "- MNIST (handwritten digits)\n",
    "- CIFAR-10 (32x32 resolution color images of 10 object classes)\n",
    "\n",
    "## Instructions\n",
    "---\n",
    "\n",
    "You should perform this assignment using Google Colab.\n",
    "* Before starting, clone this assignment using `File > Save a copy in Drive`.\n",
    "* After you're done, go through the notebook and ensure that you have answered all questions.\n",
    "* Finally, submit the ipynb `File > Download > Download .ipynb` on brightspace\n",
    "\n",
    "\n",
    "## 1. Warmup [5%]\n",
    "---\n",
    "\n",
    "It is always good practice to visually inspect your data before trying to train a model, since it lets you check for problems and get a feel for the task at hand. MNIST is a dataset of 70,000 grayscale hand-written digits (0 through 9).\n",
    "60,000 of these are training images. 10,000 are a held out test set. On the other hand, CIFAR-10 is a dataset of 60,000 color images (32 by 32 resolution) across 10 classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck). The train/test split is 50k/10k.\n",
    "\n",
    "* (a) Display 10 random images from each class of MNIST\n",
    "* (b) Do the same for each class of CIFAR-10\n",
    "\n",
    "Use `matplotlib` and ipython notebook's visualization capabilities. See [this PyTorch tutorial page](http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) for hints on how to achieve this.\n",
    "\n",
    "## 2. Training a Single Layer Network on MNIST [10%]\n",
    "---\n",
    "\n",
    "* (a) Start by running the training on MNIST and train the model for 20 epochs.\n",
    "By default, the model will train on MNIST.\n",
    "\n",
    "This will initialize a single layer model and train it on the 60,000 MNIST training images for 1 epoch (passes through the training data). The loss function ([cross_entropy](http://pytorch.org/docs/master/nn.html?highlight=cross_entropy#torch.nn.functional.cross_entropy)) computes a Logarithm of the Softmax on the output of the neural network, and then computes the negative log-likelihood w.r.t. the given `target`. The default values for the learning rate, batch size and number of epochs are given in the `options` cell of this notebook. Unless otherwise specified, use the default values throughout this assignment. Note the decrease in training loss and corresponding decrease in validation errors.\n",
    "\n",
    "* (b): Add code to plot out the network weights as images (one for each output, of size 28 by 28) after the last epoch. (Hint threads: [#1](https://discuss.pytorch.org/t/understanding-deep-network-visualize-weights/2060/2?u=smth) [#2](https://github.com/pytorch/vision#utils) )\n",
    "\n",
    "* (c): Reduce the number of training examples to just 50. (Hint: limit the iterator in the `train` function) and train the model until the loss converges. Explain what is happening to the model.\n",
    "\n",
    "## 3. Training a Multi-Layer Network on MNIST [10%]\n",
    "---\n",
    "\n",
    "* (a) Add an extra layer with 1000 hidden units and a `tanh` nonlinearity. (Hint: modify the `Net` class). Train the model for 10 epochs.\n",
    "* (b) Now set the learning rate to 10 and observe what happens during training. Give a brief explanation of your observations\n",
    "\n",
    "## 4. Training a Convolutional Network on CIFAR [25%]\n",
    "---\n",
    "\n",
    "To change over to the CIFAR-10 dataset, change the `options` cell's `dataset` variable to `'cifar10'`.\n",
    "\n",
    "- (a) Create a convolutional network with the following architecture:\n",
    "  - Convolution with 5 by 5 filters, 16 feature maps + Tanh nonlinearity.\n",
    "  - 2 by 2 max pooling (non-overlapping).\n",
    "  - Convolution with 5 by 5 filters, 128 feature maps + Tanh nonlinearity.\n",
    "  - 2 by 2 max pooling (non-overlapping).\n",
    "  - Flatten to vector.\n",
    "  - Linear layer with 64 hidden units + Tanh nonlinearity.\n",
    "  - Linear layer to 10 output units.\n",
    "\n",
    "* (b) Train it for 20 epochs on the CIFAR-10 training set. Show an image of the first layer filters.\n",
    "\n",
    "* (c) Give a breakdown of the parameters within the above model, and the overall number.\n",
    "\n",
    "Hints: [Follow the first PyTorch tutorial](http://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html) or look at the [MNIST example](https://github.com/pytorch/examples/tree/master/mnist). Also, you may speed up training if you use a GPU runtime (`RunTime > Change Runtime Type > GPU`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CrnqiscEKGWv"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "V0NBWksLKRD7"
   },
   "outputs": [],
   "source": [
    "# Options\n",
    "dataset = 'mnist' # options: 'mnist' | 'cifar10'\n",
    "batch_size = 64   # input batch size for training\n",
    "epochs = 20       # number of epochs to train\n",
    "lr = 0.01        # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ab7pqvGUKVVf"
   },
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "# This cell might take some time when you run it for the first time,\n",
    "# because it will download the datasets from the internet\n",
    "if dataset == 'mnist':\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    trainset = datasets.MNIST(root='.', train=True, download=True, transform=data_transform)\n",
    "    testset = datasets.MNIST(root='.', train=False, download=True, transform=data_transform)\n",
    "\n",
    "elif dataset == 'cifar10':\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    trainset = datasets.CIFAR10(root='.', train=True, download=True, transform=data_transform)\n",
    "    testset = datasets.CIFAR10(root='.', train=False, download=True, transform=data_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader  = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vKZ66qf0Uo2X"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "num_classes = 10\n",
    "\n",
    "def imshow(img):\n",
    "  img = img / 2 + 0.5     # unnormalize\n",
    "  # npimg = img.numpy()\n",
    "  img = torch.clamp(img, 0, 1)\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.imshow(np.transpose(img, (1, 2, 0)))\n",
    "  ax.set_facecolor('white')  # Set the background color of the figure to white\n",
    "  ax.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "# get some random training images\n",
    "class_examples = {i: [] for i in range(num_classes)}\n",
    "\n",
    "for img, label in trainset:\n",
    "    if len(class_examples[label]) < 10:\n",
    "        class_examples[label].append(img)\n",
    "    if all(len(class_examples[i]) == 10 for i in class_examples):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CEsImYDTvdP2",
    "outputId": "60f40b37-0ae3-4dcf-bf11-1b6717da5e96"
   },
   "outputs": [],
   "source": [
    "for i in class_examples.keys():\n",
    "    print(f'\\bClass: {trainset.classes[i]}')\n",
    "    imshow(torchvision.utils.make_grid(class_examples[i],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mRkBGjAEKZM0"
   },
   "outputs": [],
   "source": [
    "## network and optimizer\n",
    "if dataset == 'mnist':\n",
    "    num_inputs = 784\n",
    "elif dataset == 'cifar10':\n",
    "    num_inputs = 3072\n",
    "\n",
    "num_outputs = 10 # same for both CIFAR10 and MNIST, both have 10 classes as outputs\n",
    "num_hidden = num_inputs\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super(Net, self).__init__()\n",
    "        self.i2h = nn.Linear(num_inputs, num_hidden)\n",
    "        self.h2o = nn.Linear(num_hidden, num_outputs)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(-1, num_inputs) # reshape input to batch x num_inputs\n",
    "        # hidden = self.i2h(input)\n",
    "        # hidden = self.tanh(hidden)\n",
    "        # output = self.h2o(hidden)\n",
    "        output = self.h2o(input)\n",
    "        return output\n",
    "\n",
    "network = Net(num_inputs, num_hidden, num_outputs)\n",
    "optimizer = optim.SGD(network.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3DfrCg4-Kfq6"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for i in range(1, epoch + 1):\n",
    "    #   total_loss = 0\n",
    "      for batch_idx, (data, target) in enumerate(train_loader):\n",
    "          optimizer.zero_grad()\n",
    "          output = network(data)\n",
    "          loss = F.cross_entropy(output, target)\n",
    "        #   total_loss += loss.detach().cpu().item()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          # if batch_idx >= 50:\n",
    "          #   break\n",
    "    #   print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "    #         i+1, batch_idx, len(train_loader),\n",
    "    #         100. * batch_idx / len(train_loader), total_loss/len(train_loader)))\n",
    "\n",
    "          if batch_idx % 100 == 0:\n",
    "              print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                  i+1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                  100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        output = network(data)\n",
    "        test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c52XmoeCKja2",
    "outputId": "3274a7d8-f8cc-4033-b6ac-f9e09b0db803"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = Net(num_inputs, num_hidden, num_outputs)\n",
    "optimizer = optim.SGD(network.parameters(), lr=lr)\n",
    "# train(20)\n",
    "\n",
    "# torch.save(network.state_dict(), f'{dataset}_model.pth')\n",
    "\n",
    "network.load_state_dict(torch.load(f'{dataset}_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Nfl06zkKmfX",
    "outputId": "1f1b98dc-16bf-4497-c5f5-b0d2dc584387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2713, Accuracy: 9242/10000 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DB6-Mo4sdgoh"
   },
   "source": [
    "### 2(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "# import visdom\n",
    "\n",
    "# vis = visdom.Visdom()\n",
    "# weights = network.h2o.weight.data.view(-1, 28, 28).numpy()\n",
    "# for i in range(num_classes):\n",
    "#     vis.heatmap(weights[i], opts=dict(title=f'{trainset.classes[i]}'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 3\n",
    "num_outputs = 10 # same for both CIFAR10 and MNIST, both have 10 classes as outputs\n",
    "hidden_size = [16, 128]\n",
    "fc_size = [128*5*5, 64]\n",
    "class enhanced_net(nn.Module):\n",
    "    def __init__(self, num_inputs, hidden_size, fc_size, num_outputs):\n",
    "        super(enhanced_net, self).__init__() \n",
    "        modules = []\n",
    "        for i in hidden_size:\n",
    "            modules.append(nn.Conv2d(num_inputs, i, kernel_size=5,))\n",
    "            modules.append(nn.Tanh())\n",
    "            modules.append(nn.MaxPool2d(2, padding = 0))\n",
    "            num_inputs = i\n",
    "        self.conv = nn.Sequential(*modules)\n",
    "        self.fc = nn.Sequential(nn.Linear(fc_size[-2], fc_size[-1]),\n",
    "                                nn.Tanh(),\n",
    "                                nn.Linear(fc_size[-1], num_outputs))\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv(input)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = enhanced_net(num_inputs = num_inputs, hidden_size = hidden_size, fc_size= fc_size, num_outputs = num_outputs)\n",
    "optimizer = optim.SGD(network.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(20)\n",
    "\n",
    "torch.save(network.state_dict(), f'{dataset}_model_20.pth')\n",
    "network.load_state_dict(torch.load(f'{dataset}_model_20.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9351, Accuracy: 6721/10000 (67%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.0.weight        1200                \n",
      "conv.0.bias          16                  \n",
      "conv.3.weight        51200               \n",
      "conv.3.bias          128                 \n",
      "fc.0.weight          204800              \n",
      "fc.0.bias            64                  \n",
      "fc.2.weight          640                 \n",
      "fc.2.bias            10                  \n",
      "total params\t\t258058              \n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "for name, param in network.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        layer_params = param.numel()\n",
    "        total_params += layer_params\n",
    "        print(f\"{name:<20} {layer_params:<20}\")\n",
    "\n",
    "print(f\"total params\\t\\t{total_params:<20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "enhanced_net                             [32, 10]                  --\n",
       "├─Sequential: 1-1                        [32, 128, 5, 5]           --\n",
       "│    └─Conv2d: 2-1                       [32, 16, 28, 28]          1,216\n",
       "│    └─Tanh: 2-2                         [32, 16, 28, 28]          --\n",
       "│    └─MaxPool2d: 2-3                    [32, 16, 14, 14]          --\n",
       "│    └─Conv2d: 2-4                       [32, 128, 10, 10]         51,328\n",
       "│    └─Tanh: 2-5                         [32, 128, 10, 10]         --\n",
       "│    └─MaxPool2d: 2-6                    [32, 128, 5, 5]           --\n",
       "├─Sequential: 1-2                        [32, 10]                  --\n",
       "│    └─Linear: 2-7                       [32, 64]                  204,864\n",
       "│    └─Tanh: 2-8                         [32, 64]                  --\n",
       "│    └─Linear: 2-9                       [32, 10]                  650\n",
       "==========================================================================================\n",
       "Total params: 258,058\n",
       "Trainable params: 258,058\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 201.33\n",
       "==========================================================================================\n",
       "Input size (MB): 0.39\n",
       "Forward/backward pass size (MB): 6.51\n",
       "Params size (MB): 1.03\n",
       "Estimated Total Size (MB): 7.93\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(network, input_size=(32, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conv_layer = network.conv[0]  # Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "first_conv_weights = first_conv_layer.weight.data.cpu()  # Shape: [16, 3, 5, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize using torchvision's make_grid\n",
    "plt.figure(figsize=(8, 8))\n",
    "grid = torchvision.utils.make_grid(first_conv_weights, nrow=4, normalize=True, scale_each=True)\n",
    "plt.imshow(grid.permute(1, 2, 0))  # Change the order of dimensions to (H, W, C) for display\n",
    "plt.title(\"Filters of the first conv layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
