{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\tianc\\\\scrapfly-scrapers\\\\etsy-scraper\\\\results'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections.abc import MutableMapping\n",
    "import json\n",
    "import csv\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "def _write_to_csv(csv_file, files):\n",
    "    headers = ['Name', 'URL', 'SKU', 'Description', 'Category', \n",
    "               'Brand','Rating Value', 'Review Count', 'Price', 'Price Currency', \n",
    "               'Availability', 'Material', 'Review', 'Rate', 'Reviewer', 'Review Date']\n",
    "    \n",
    "    # Write headers to the CSV file\n",
    "    for f in files:\n",
    "        with open(f, 'r', encoding = 'utf-8') as file:\n",
    "            f = json.load(file)\n",
    "            with open(csv_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                if not os.path.exists(csv_file) or os.stat(csv_file).st_size == 0:\n",
    "                    writer.writerow(headers)\n",
    "                for product in f:\n",
    "                    # For each product, we extract required data, handle missing values with `.get()` method\n",
    "                    url = product.get('url', '')\n",
    "                    name = product.get('name', '')\n",
    "                    sku = product.get('sku', '')\n",
    "                    description = product.get('description', '').replace('\\n', ' ')\n",
    "                    category = product.get('category', '')\n",
    "                    \n",
    "                    brand = product.get('brand', {}).get('name', '')\n",
    "                    \n",
    "                    rating_value = product.get('aggregateRating', {}).get('ratingValue', '')\n",
    "                    total_review_count = product.get('aggregateRating', {}).get('reviewCount', '')\n",
    "\n",
    "                    price = product.get('offers', {}).get('price', '')\n",
    "                    price_currency = product.get('offers', {}).get('priceCurrency', '')\n",
    "                    availability = product.get('offers', {}).get('availability', '')\n",
    "                    \n",
    "                    material = product.get('material', '')\n",
    "                    \n",
    "                    # Handling the first review data\n",
    "                    if 'review' in product and len(product['review']) > 0:\n",
    "                        for item in product['review']:\n",
    "                            review = item.get('reviewBody', '')\n",
    "                            rate = item.get('reviewRating', {}).get('ratingValue', '') \n",
    "                            reviewer = item.get('author', {}).get('name', '') \n",
    "                            review_date = item.get('datePublished', '')\n",
    "                            writer.writerow([name, url, sku, description, category, \n",
    "                            brand, rating_value, total_review_count, price, price_currency, \n",
    "                            availability, material, review, rate, reviewer, review_date])\n",
    "                    else:\n",
    "                        review = rate = reviewer = review_date = ''\n",
    "                        writer.writerow([name, url, sku, description, category, \n",
    "                        brand, rating_value, total_review_count, price, price_currency, \n",
    "                        availability, material, review, rate, reviewer, review_date])\n",
    "                    \n",
    "                    # Write the row for each product\n",
    "\n",
    "\n",
    "    print(f'Data has been successfully written to {csv_file}')\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully written to etsy_reviews_.csv\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'etsy_reviews_.csv'\n",
    "\n",
    "files = ['products_null.json']\n",
    "_write_to_csv(csv_file, files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('etsy_reviews_.csv')\n",
    "file = filcompany.dropna(subset = 'Review')\n",
    "filcompany.to_excel('etsy_r.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrustPilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import MutableMapping\n",
    "import json\n",
    "import csv\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "def _write_to_csv(csv_file, files):\n",
    "    headers = ['Company', 'Website', 'Id', 'Source',\n",
    "               'Trust Score (if from TrustPilot)', 'Review Count', 'Review Source','Title', 'Rate', 'Review', 'Likes', 'Reply', 'Reviewer', 'Review Date', 'Total Reviews by Reviewer', \n",
    "               'Language', 'Country Code']\n",
    "    \n",
    "    # Write headers to the CSV file\n",
    "    for i in range(0, len(files), 2):\n",
    "        company = files[i]\n",
    "        reviews = files[i+1]\n",
    "        with open(company, 'r', encoding = 'utf-8') as f1, open(reviews, 'r', encoding = 'utf-8') as f2:    \n",
    "            company = json.load(f1)[0]\n",
    "            reviews = json.load(f2)\n",
    "            with open(csv_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                if not os.path.exists(csv_file) or os.stat(csv_file).st_size == 0:\n",
    "                    writer.writerow(headers)\n",
    "                Company =  company.get('companyDetails', {}).get('displayName', '')\n",
    "                Website = company.get('companyDetails', {}).get('websiteUrl', '')\n",
    "                Id = company.get('companyDetails', {}).get('id', '')\n",
    "                Source = company.get('pageUrl', '')\n",
    "                Trust_Score = company.get('companyDetails', {}).get('trustScore', '')\n",
    "                Review_Count = company.get('companyDetails', {}).get('numberOfReviews', '')\n",
    "                for r in reviews:\n",
    "                    ReviewSource = r.get('labels', {}).get('verification', {}).get('reviewSourceName', '')\n",
    "                    Title = r.get('title', '')\n",
    "                    Rate = r.get('rating', '')\n",
    "                    Review = r.get('text', '')\n",
    "                    Likes = r.get('likes', '')\n",
    "                    Reply = r.get('reply', '')\n",
    "                    Reviewer = r.get('consumer', {}).get('displayName', '') or r.get('consumer', {}).get('id', '')\n",
    "                    ReviewDate = r.get('dates', {}).get('publishedDate', '')\n",
    "                    TotalReviewsbyReviewer = r.get('consumer', {}).get('numberOfReviews', '')\n",
    "                    Language = r.get('language', '')   \n",
    "                    CountryCode = r.get('consumer', {}).get('countryCode', '') \n",
    "                    writer.writerow([Company, Website, Id, Source, Trust_Score, Review_Count, ReviewSource, \n",
    "                                            Title, Rate, Review, Likes, Reply, Reviewer, ReviewDate, TotalReviewsbyReviewer, \n",
    "                                            Language, CountryCode])\n",
    "                    \n",
    "    print(f'Data has been successfully written to {csv_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tianc\\scrapfly-scrapers\\trustpilot-scraper\\results\n",
      "Data has been successfully written to trustpilot_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "%cd  ~/scrapfly-scrapers/trustpilot-scraper/results/\n",
    "\n",
    "csv_file = 'trustpilot_reviews.csv'\n",
    "files = ['companies.json','reviews.json',\n",
    "         'companies_0.json', 'reviews_0.json']\n",
    "\n",
    "\n",
    "_write_to_csv(csv_file, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('trustpilot_reviews.csv')\n",
    "file.head()\n",
    "# file = file.dropna(subset = 'Review')\n",
    "file.to_excel('trustpilot_reviews.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etsy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
